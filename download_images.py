from icrawler.builtin import BingImageCrawler
import os

# ãƒ‰ã‚¤ãƒ„èªžã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾žæ›¸
search_terms = {
   search_terms = {
    "biowaste": [
        "Biotonne Paderborn",
        "BiomÃ¼ll Paderborn",
        "Obst- und GemÃ¼sereste Biotonne",
        "Kompostierbare AbfÃ¤lle Biotonne"
    ],
    "paper": [
        "Papiertonne Paderborn",
        "Altpapiercontainer Paderborn",
        "Zeitungen Papiertonne",
        "Kartons Papiertonne"
    ],
    "plastic": [
        "Wertstofftonne Paderborn",
        "Plastik Wertstofftonne",
        "Kunststoff Metall Wertstofftonne",
        "Joghurtbecher Wertstofftonne"
    ],
    "glass": [
        "Glascontainer Paderborn",
        "Altglas Paderborn",
        "GetrÃ¤nkeflaschen Glascontainer",
        "WeiÃŸglas GrÃ¼n Glascontainer"
    ],
    "pfand": [
        "Pfandflaschen Automat Paderborn",
        "Einweg Pfandflasche Paderborn",
        "Mehrweg Pfandflasche Paderborn"
    ],
    "residual": [
        "RestmÃ¼ll Paderborn",
        "Restabfalltonne Paderborn",
        "Hygieneartikel RestmÃ¼ll",
        "verschmutzte Verpackungen RestmÃ¼ll"
    ]
}

}

output_dir = "dataset"
images_per_category = 150

os.makedirs(output_dir, exist_ok=True)

for category, keywords in search_terms.items():
    save_path = os.path.join(output_dir, category)
    os.makedirs(save_path, exist_ok=True)

    crawler = BingImageCrawler(storage={"root_dir": save_path})

    for keyword in keywords:
        print(f"ðŸ‡©ðŸ‡ª '{keyword}' â†’ {category}")
        crawler.crawl(keyword=keyword, max_num=images_per_category // len(keywords))
